{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "b4VoCHZKjNDy",
        "rN6H42CVBStd",
        "KPfidpDHEmzt",
        "MNrFtMR4JKR8"
      ],
      "mount_file_id": "149RtO-kMj-tN6wm7S2LbWQRFytx5H-Fl",
      "authorship_tag": "ABX9TyM+D6uUSLcndHz51SzqNlQZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Schiweppes/My-Deep-Learning-Notebooks/blob/main/Github_Histopathology_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install imagecodecs\n",
        "%pip install patchify"
      ],
      "metadata": {
        "id": "HI5OcccAjsmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import imagecodecs\n",
        "from patchify import patchify,unpatchify\n",
        "import glob\n",
        "\n",
        "from typing import Tuple\n",
        "import os\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, \\\n",
        "concatenate, BatchNormalization, Activation, add\n",
        "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf \n",
        "\n",
        "import tensorflow.keras as keras"
      ],
      "metadata": {
        "id": "x0JMsEyQeZaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "b4VoCHZKjNDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(path:str = None)->Tuple[np.ndarray,np.ndarray,int]:\n",
        "    \"\"\"\n",
        "    Returns the first image and first label as a numpy array\n",
        "\n",
        "            Keyword arguments:\n",
        "                    path (str) : Absolute path to Dataset Folder\n",
        "\n",
        "                 ..\\Dataset Folder\n",
        "                    |--\\Images\\\n",
        "                        |--image1.png\n",
        "                        ...         \n",
        "                    |--\\Labels\\\n",
        "                        |--image1_label.png\n",
        "                        ...\n",
        "\n",
        "                    \n",
        "            Returns:\n",
        "                    image(np.ndarray), label(np.ndarray),size(int) : image, label and size of the dataset\n",
        "    \"\"\"\n",
        "    if not path:\n",
        "        image = np.array(imageio.imread('/content/drive/MyDrive/histopatoloji\\\n",
        "/lab_crop/ds2_cropped_1.png'))\n",
        "        label_image = np.array(imageio.imread('/content/drive/MyDrive/histopat\\\n",
        "oloji/lab_crop/ds2_cropped_1-labels.png'))\n",
        "        return image,label_image,1\n",
        "        \n",
        "\n",
        "    else:\n",
        "\n",
        "        image_path = path + r\"/Images\"\n",
        "        label_path = path + r\"/Labels\"\n",
        "\n",
        "\n",
        "        image_names = sorted(os.listdir(image_path))\n",
        "        label_names = sorted(os.listdir(label_path))\n",
        "\n",
        "        size1 = len(image_names)\n",
        "        size2 = len(label_names)\n",
        "\n",
        "        assert size1 == size2, \"image and label mismatch!\"\n",
        "\n",
        "        image_sample = f\"{image_path}/{image_names[0]}\"\n",
        "\n",
        "        label_sample = f\"{label_path}/{label_names[0]}\"\n",
        "\n",
        "\n",
        "        img = np.array(imageio.imread(image_sample))\n",
        "        label = np.array(imageio.imread(label_sample)) ## np array sonra\n",
        "\n",
        "        return img,label,size1"
      ],
      "metadata": {
        "id": "35LVSNq--2G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb2gray(rgb:imageio.core.util.Array)->np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns a gray scale image\n",
        "    Keyword arguments:\n",
        "        rgb_image(imageio.core.util.Array) : Image to convert to grayscale\n",
        "\n",
        "    Returns:\n",
        "        gray(np.ndarray) : Grayscale image\n",
        "    \"\"\"\n",
        "\n",
        "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
        "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "\n",
        "    return np.array(gray)"
      ],
      "metadata": {
        "id": "H_St0_7nYeCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_data(data:np.ndarray,patch_size:Tuple[int],step_size:int = 256)-> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns patches of given data\n",
        "\n",
        "    Keyword Arguments:\n",
        "        data(np.ndarray) : data to be patched.\n",
        "        patch_size((int,int,_)) : patch size\n",
        "        step_size(int) : step size of the patches should equal to patch size\n",
        "    Returns:\n",
        "        patches(np.ndarray) : patches of data\n",
        "    \"\"\"\n",
        "    if len(data.shape) == 3 and len(patch_size) == 2:\n",
        "        raise Exception(\"Image should be patched by 256x256x3\")\n",
        "\n",
        "    assert step_size == patch_size[0], \"Differency in step_size and patch_size\\\n",
        " causes overlap!\"\n",
        "\n",
        "    data = patchify(data,patch_size, step_size)\n",
        "\n",
        "    if data.shape[2] == 1:\n",
        "        data = np.squeeze(data, axis=2)\n",
        "        return data.shape,data.reshape((-1,256,256,3))\n",
        "    else:\n",
        "        return data.shape,data.reshape((-1,256,256))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7aF9koTHbCOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graphify(idxs,fig_size = 15):\n",
        "    \"\"\"\n",
        "    Plots the desired amount of image and label patch\n",
        "\n",
        "    Keyword Arguments:\n",
        "    idxs(List[int]) : indexes of data to be plotted\n",
        "    fig_size(int) : size of each subplot\n",
        "\n",
        "    \"\"\"\n",
        "    n = len(idxs)\n",
        "    plt_idx = 0\n",
        "    fig,ax = plt.subplots(n, 2, figsize=(fig_size,fig_size))\n",
        "    fig.tight_layout()\n",
        "    ax[0][0].set_title('Original Image')\n",
        "    ax[0][1].set_title('Masked Image')\n",
        "    for i in idxs: \n",
        "        for j in range(2):\n",
        "            image = image_patches[i,:,:,:]\n",
        "            label = label_patches[i,:,:]\n",
        "            if j % 2: \n",
        "                ax[plt_idx,j].imshow(label,cmap='gray')\n",
        "                \n",
        "            else:\n",
        "                ax[plt_idx,j].imshow(image,cmap='gray')\n",
        "                \n",
        "        plt_idx += 1"
      ],
      "metadata": {
        "id": "KPQQNsxRhv3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_masks(label_patches:np.ndarray,mask_mean:float = 0.5)->list:  \n",
        "    \"\"\"\n",
        "    Returns patch indexes of labels\n",
        "\n",
        "    Keyword Arguments:\n",
        "    label_patches(np.ndarray) : Array of label patches\n",
        "    mask_mean(float) : limit value to check if mask is available in that patch\n",
        "\n",
        "    Returns:\n",
        "    mask_list(List[int]) : List of integers\n",
        "\n",
        "    \"\"\"\n",
        "    mask_list = list()\n",
        "    for idx,i in enumerate(label_patches):\n",
        "        if i.mean() > mask_mean:\n",
        "            mask_list.append(idx)\n",
        "    return mask_list"
      ],
      "metadata": {
        "id": "AWt_NebpiVGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_data(path:str = None)->Tuple[np.ndarray,np.ndarray,int]:\n",
        "    \"\"\"\n",
        "    Returns the first image and first label as a numpy array\n",
        "\n",
        "            Keyword arguments:\n",
        "                    path (str) : Absolute path to Dataset Folder\n",
        "\n",
        "                 ..\\Dataset Folder\n",
        "                    |--\\Images\\\n",
        "                        |--image1.png\n",
        "                        ...         \n",
        "                    |--\\Labels\\\n",
        "                        |--image1_label.tif\n",
        "                        ...\n",
        "\n",
        "                    \n",
        "            Returns:\n",
        "                    image(np.ndarray), label(np.ndarray),size(int) : image, label and size of the dataset\n",
        "    \"\"\"\n",
        "    if not path:\n",
        "        image = np.array(imageio.imread('/content/drive/MyDrive/histopatoloji\\\n",
        "/lab_crop/ds2_cropped_1.png'))\n",
        "        label_image = np.array(imageio.imread('/content/drive/MyDrive/histopat\\\n",
        "oloji/lab_crop/ds2_cropped_1-labels.png'))\n",
        "        return image,label_image,1\n",
        "        \n",
        "\n",
        "    else:\n",
        "\n",
        "        image_path = path + r\"/Images\"\n",
        "        label_path = path + r\"/Labels\"\n",
        "\n",
        "\n",
        "        image_names = os.listdir(image_path)\n",
        "        label_names = os.listdir(label_path)\n",
        "\n",
        "        for i,j in zip(sorted(image_names),sorted(label_names)):\n",
        "            print(\"*************\\n\",i,j)\n",
        "            image_sample = f\"{image_path}/{i}\"\n",
        "\n",
        "            label_sample = f\"{label_path}/{j}\"\n",
        "            img = np.array(imageio.imread(image_sample))\n",
        "            label = np.array(imageio.imread(label_sample))\n",
        "            yield (img,label)"
      ],
      "metadata": {
        "id": "1Cvv8cy2spd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_augment(x_patch,y_patch,augment:bool = False):\n",
        "    x_train,x_test,y_train,y_test = split(x_patch,\n",
        "                                      y_patch,\n",
        "                                      test_size = test_split_size)\n",
        "    datagen = None\n",
        "\n",
        "    if augment:\n",
        "        datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                rotation_range = rotation_range,\n",
        "                                horizontal_flip =horizontal_flip,\n",
        "                                vertical_flip = vertical_flip,\n",
        "                                width_shift_range=width_shift_range,\n",
        "                                height_shift_range=height_shift_range)\n",
        "    else:\n",
        "        datagen = ImageDataGenerator(rescale=1./255)\n",
        "        \n",
        "    train_dataset_patch = datagen.flow(x = x_train,\n",
        "                                   y = y_train,\n",
        "                                   batch_size = BATCH_SIZE,\n",
        "                                   seed = SEED)\n",
        "\n",
        "    valid_dataset_patch = datagen.flow(x = x_test,\n",
        "                                   y = y_test,\n",
        "                                   batch_size = BATCH_SIZE,\n",
        "                                   seed = SEED)\n",
        "    train_step,val_step = len(x_train) // BATCH_SIZE,len(x_test)//BATCH_SIZE\n",
        "    return train_dataset_patch,valid_dataset_patch,train_step,val_step  "
      ],
      "metadata": {
        "id": "lZCcR1oOsvHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(dataset_folder:str):\n",
        "    \"\"\"\n",
        "    One function to run them all.\n",
        "\n",
        "    Keyword argumnts:\n",
        "        path : Main path to Dataset Folder\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    for idx,(img,label) in enumerate(yield_data(path=dataset_folder)):\n",
        "        label = rgb2gray(label)\n",
        "\n",
        "        shape,image_patches = patch_data(img,(256,256,3),256)\n",
        "        shape,label_patches = patch_data(label,(256,256),256)\n",
        "        \n",
        "        label_patches = np.where(label_patches<50,label_patches,255.)\n",
        "        del img,label\n",
        "        print(f\"patch size : {image_patches.shape[0]}\")\n",
        "\n",
        "        assert label_patches.shape[:] == image_patches.shape[:-1]\n",
        "\n",
        "        train_dataset,valid_dataset,train_step,val_step = preprocess_augment(\n",
        "                                                         image_patches,\n",
        "                                                         label_patches,\n",
        "                                                         augment = False)\n",
        "        del image_patches,label_patches\n",
        "        ## for loading our model\n",
        "        custom_objects = {\n",
        "                  'FocalTverskyLoss':FocalTverskyLoss,\n",
        "                  'log_cosh_dice_loss':log_cosh_dice_loss,\n",
        "                  'sparse_categorical_crossentropy': keras.metrics.SparseCategoricalCrossentropy(from_logits = True),\n",
        "                  'dice_loss':dice_loss,\n",
        "                  'jaccard':jaccard,\n",
        "                  'dice_coef':dice_coef,\n",
        "                  'sensitivity':sensitivity,\n",
        "                  'specificity':specificity}\n",
        "\n",
        "        print(f\"Training {idx+1}th image:\")\n",
        "        if len(os.listdir(checkpoint_path)) != 0:\n",
        "            print(\"Loading trained model ...\")\n",
        "\n",
        "            loaded_model = keras.models.load_model(checkpoint_path,\n",
        "                                                   custom_objects=custom_objects)\n",
        "\n",
        "            loaded_model.compile(optimizer = keras.optimizers.Adam(\n",
        "                   learning_rate = learning_rate),\n",
        "                   loss = custom_objects[loss_function],\n",
        "                   metrics = [jaccard,dice_coef,],\n",
        "                   )\n",
        "            print(\"Model is loaded and compiled!\")\n",
        "            \n",
        "            loaded_model.fit(train_dataset,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         epochs= 2,\n",
        "                         callbacks = callbacks,\n",
        "                         workers = -1,\n",
        "                         validation_data = valid_dataset,\n",
        "                         validation_steps = (val_step),\n",
        "                         steps_per_epoch=(train_step))\n",
        "            tf.keras.backend.clear_session()\n",
        "        else:\n",
        "            print(\"Creating new model...\")\n",
        "            \n",
        "            model = MultiResUnet(256,256,3)\n",
        "            model.compile(optimizer = keras.optimizers.Adam(\n",
        "                   learning_rate = learning_rate),\n",
        "                   loss = custom_objects[loss_function],\n",
        "                   metrics = [jaccard,dice_coef,sensitivity,specificity],\n",
        "                   )\n",
        "            print(\"Model is created and compiled!\")\n",
        "\n",
        "            model.fit(train_dataset,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         epochs= 2,\n",
        "                         callbacks = callbacks,\n",
        "                         workers = -1,\n",
        "                         validation_data = valid_dataset,\n",
        "                         validation_steps = (val_step),\n",
        "                         steps_per_epoch=(train_step))\n",
        "            tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "mC3ECHXIs47l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruct_patch(patch:np.ndarray,patch_shape):\n",
        "    \"\"\" \n",
        "    Reconstruct the whole image.\n",
        "\n",
        "    Keyword Arguments:\n",
        "    patch(np.ndarray) : patch array to reconstruct\n",
        "    patch_shape(tuple) : necessary shape information to reconstruct\n",
        "\n",
        "    Returns:\n",
        "    Reconstructed numpy array.\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    patch_size = 256\n",
        "    shape = patch_shape\n",
        "    if shape[-1] == 3:\n",
        "        image_patches = patch.reshape((shape[0],shape[1],256,256,3))\n",
        "        image_patches = np.expand_dims(image_patches,2)\n",
        "        return unpatchify(image_patches,(shape[0]*256,shape[1]*256,3))\n",
        "    else:\n",
        "        patches = patch.reshape((shape[0],shape[1],256,256))\n",
        "        return unpatchify(patches,(shape[0]*256,shape[1]*256))"
      ],
      "metadata": {
        "id": "qUFJw0Ya3L3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graphify_prediction(img_patch:np.ndarray, pred_patch:np.ndarray,idx_list:list,fig_size:int = 15):\n",
        "    \"\"\"\n",
        "    Plots images and corresponding predictions\n",
        "\n",
        "    Keyword Arguments:\n",
        "    img_patch(np.ndarray) : image patch\n",
        "    pred_patch(np.ndarray) : prediction patch\n",
        "    idx_list (list) : list of masks\n",
        "    fig_size (int) : size of figure\n",
        "\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if pred_patch.shape[-1] == 1:\n",
        "        pred_patch = np.squeeze(pred_patch,axis = -1)\n",
        "\n",
        "    n = len(idx_list)\n",
        "    plt_idx = 0\n",
        "    fig,ax = plt.subplots(n, 2, figsize=(fig_size,fig_size))\n",
        "    fig.tight_layout()\n",
        "    ax[0][0].set_title('Image')\n",
        "    ax[0][1].set_title('Prediction')\n",
        "    for i in idx_list: \n",
        "        for j in range(2):\n",
        "            image = img_patch[i,:,:,:]\n",
        "            pred = pred_patch[i,:,:]\n",
        "            if j % 2: \n",
        "                ax[plt_idx,j].imshow(pred,cmap='gray')\n",
        "                \n",
        "            else:\n",
        "                ax[plt_idx,j].imshow(image,cmap='gray')\n",
        "                \n",
        "        plt_idx += 1"
      ],
      "metadata": {
        "id": "5fsUUtCTFZiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "rN6H42CVBStd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu'):\n",
        "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "mwg3_9w4CSa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2)):\n",
        "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "mywDr7SWCSWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MultiResBlock(U, inp, alpha = 1.67):\n",
        "    W = alpha * U\n",
        "\n",
        "    shortcut = inp\n",
        "\n",
        "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
        "                         int(W*0.5), 1, 1, activation='relu', padding='same')\n",
        "\n",
        "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "SKglmO34CSTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResPath(filters, length, inp):\n",
        "    shortcut = inp\n",
        "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                         activation='relu', padding='same')\n",
        "\n",
        "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    for i in range(length-1):\n",
        "\n",
        "        shortcut = out\n",
        "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                             activation='relu', padding='same')\n",
        "\n",
        "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "        out = add([shortcut, out])\n",
        "        out = Activation('relu')(out)\n",
        "        out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "Wno6D4ncCSRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MultiResUnet(height, width, n_channels):\n",
        "    inputs = Input((height, width, n_channels))\n",
        "\n",
        "    mresblock1 = MultiResBlock(32, inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
        "    mresblock1 = ResPath(32, 4, mresblock1)\n",
        "\n",
        "    mresblock2 = MultiResBlock(32*2, pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
        "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
        "\n",
        "    mresblock3 = MultiResBlock(32*4, pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
        "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
        "\n",
        "    mresblock4 = MultiResBlock(32*8, pool3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
        "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
        "\n",
        "    mresblock5 = MultiResBlock(32*16, pool4)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(\n",
        "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
        "    mresblock6 = MultiResBlock(32*8, up6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(\n",
        "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
        "    mresblock7 = MultiResBlock(32*4, up7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(\n",
        "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
        "    mresblock8 = MultiResBlock(32*2, up8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
        "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
        "    mresblock9 = MultiResBlock(32, up9)\n",
        "\n",
        "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid') ## sigmoid\n",
        "    \n",
        "    model = keras.models.Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "qAFKMuGPCSLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Losses and Metrics\n",
        "Loss Functions and Metrics"
      ],
      "metadata": {
        "id": "KPfidpDHEmzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 1e-5\n",
        "smooth = 1\n",
        "ALPHA = 0.5\n",
        "BETA = 0.5\n",
        "GAMMA = 1\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def log_cosh_dice_loss(y_true, y_pred):\n",
        "        x = dice_loss(y_true, y_pred)\n",
        "        return tf.math.log((tf.exp(x) + tf.exp(-x)) / 2.0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def FocalTverskyLoss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):\n",
        "    \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = K.flatten(inputs)\n",
        "        targets = K.flatten(targets)\n",
        "        \n",
        "        #True Positives, False Positives & False Negatives\n",
        "        TP = K.sum((inputs * targets))\n",
        "        FP = K.sum(((1-targets) * inputs))\n",
        "        FN = K.sum((targets * (1-inputs)))\n",
        "               \n",
        "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
        "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
        "        \n",
        "        return FocalTversky"
      ],
      "metadata": {
        "id": "YlOl-T9wEjWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metric Functions**"
      ],
      "metadata": {
        "id": "Mo2FogQjuO83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 0.0\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    \n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def jaccard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "    return intersection/union\n",
        "\n",
        "def sensitivity(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        return true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "def specificity( y_true, y_pred):\n",
        "        true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "        possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
        "        return true_negatives / (possible_negatives + K.epsilon())"
      ],
      "metadata": {
        "id": "23VMMcBlGcxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters\n"
      ],
      "metadata": {
        "id": "lSmije5Smpbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocess Parameters\n",
        "BATCH_SIZE = 4        #@param {type:\"integer\"}\n",
        "IMG_SIZE = 256        #@param {type:\"integer\"}\n",
        "SEED = 727            #@param {type:\"integer\"}\n",
        "test_split_size = 0.2 #@param {type:\"number\"}"
      ],
      "metadata": {
        "id": "n93EnavFmvKP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Augmentation Parameters\n",
        "rotation_range = 135#@param {type:\"slider\",min:0,max:360,step:45}\n",
        "horizontal_flip = True#@param{type:\"boolean\"}\n",
        "vertical_flip = True#@param{type:\"boolean\"}\n",
        "width_shift_range=0.2 #@param {type:\"number\"}\n",
        "height_shift_range=0.2 #@param {type:\"number\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AsKOt8k6oArr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compile Parameters\n",
        "learning_rate = 1e-2#@param {type:\"number\"}\n",
        "loss_function = \"dice_loss\" #@param [\"sparse_categorical_crossentropy\",\"FocalTverskyLoss\",\"dice_loss\",\"log_cosh_dice_loss\"]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WZM-p3G3q6sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Callback Parameters\n",
        "reduce_lr_factor = 0.5 #@param {type:\"number\"}\n",
        "reduce_lr_monitor = 'val_loss'#@param [\"val_loss\",\"val_jaccard\",\"val_dice_coef\",\"val_sensitivity\",\"val_specificity\"]\n",
        "reduce_patience = 2 #@param {type:\"integer\"}\n",
        "reduce_min_lr = 1e-5 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/histopatoloji/auto_model_dummy\" #@param [\"/content/drive/MyDrive/histopatoloji/Model\",\"/content/drive/MyDrive/histopatoloji/auto_model_dummy\"]\n",
        "checkpoint_monitor = 'val_loss'#@param [\"val_loss\",\"val_jaccard\",\"val_dice_coef\",\"val_sensitivity\",\"val_specificity\"]\n",
        "checkpoint_verbose = 1#@param [0,1,2]\n",
        "checkpoint_save_best_only = True #@param {type:\"boolean\"}\n",
        "checkpoint_save_weights_only=False #@param {type:\"boolean\"}\n",
        "checkpoint_mode='auto' #@param [\"auto\",\"min\",\"max\"]\n",
        "\n",
        "early_stop_monitor = 'val_loss'#@param [\"val_loss\",\"val_jaccard\",\"val_dice_coef\",\"val_sensitivity\",\"val_specificity\"]\n",
        "early_stop_patience=3 #@param type:\"integer\"\n",
        "early_stop_verbose = 0 #@param [0,1,2]\n",
        "eary_stop_mode = 'min' #@param [\"auto\",\"min\",\"max\"]\n"
      ],
      "metadata": {
        "id": "Q9z7sp_9vdsm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=reduce_lr_monitor,\n",
        "                                              factor=reduce_lr_factor ,\n",
        "                                              patience=reduce_patience,\n",
        "                                              min_lr=reduce_min_lr)\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    filepath =checkpoint_path,\n",
        "    monitor=checkpoint_monitor,\n",
        "    verbose=checkpoint_verbose,\n",
        "    save_best_only=checkpoint_save_best_only,\n",
        "    save_weights_only=checkpoint_save_weights_only,\n",
        "    mode=checkpoint_mode,\n",
        "    save_freq='epoch',\n",
        "    options=None,\n",
        "    initial_value_threshold=None,\n",
        ")\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor=early_stop_monitor,\n",
        "    min_delta=0,\n",
        "    patience=early_stop_patience,\n",
        "    verbose=early_stop_verbose,\n",
        "    mode=eary_stop_mode,\n",
        "    baseline=None,\n",
        "    restore_best_weights=False\n",
        ")\n",
        "\n",
        "callbacks = [reduce_lr,checkpoint,early_stop] # earlystop"
      ],
      "metadata": {
        "id": "tTcCzY_EUldB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "7YgQFSbTU1Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ABSOLUTE\n",
        "Main function to execute all at once."
      ],
      "metadata": {
        "id": "oIi0Xf_RL2cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main(dataset_folder = '/content/drive/MyDrive/histopatoloji/ev_crop_3') ## my_data"
      ],
      "metadata": {
        "id": "VYX-S3JKL6_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**"
      ],
      "metadata": {
        "id": "9HOgYyVi9GKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_objects = {'FocalTverskyLoss':FocalTverskyLoss,\n",
        "                  'log_cosh_dice_loss':log_cosh_dice_loss,\n",
        "                  'sparse_categorical_crossentropy': keras.metrics.SparseCategoricalCrossentropy(from_logits = True),\n",
        "                  'dice_loss':dice_loss,\n",
        "                  'jaccard':jaccard,\n",
        "                  'dice_coef':dice_coef,\n",
        "                  'sensitivity':sensitivity,\n",
        "                  'specificity':specificity}\n",
        "loaded_model = keras.models.load_model('/content/drive/MyDrive/histopatoloji/auto_model_dummy',custom_objects = custom_objects)"
      ],
      "metadata": {
        "id": "lwSnG_DV8v5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## read data for prediction\n",
        "img,label,dataset_size = read_data('/content/drive/MyDrive/histopatoloji/buse')\n",
        "label = rgb2gray(label)\n",
        "img_shape = img.shape\n",
        "label_shape = label.shape\n",
        "\n",
        "img_patch_shape, image_patches = patch_data(img,(256,256,3),256) # use for reconstruction\n",
        "label_patch_shape, label_patches = patch_data(label,(256,256),256)\n",
        "label_patches = np.where(label_patches<50,label_patches,255.)\n",
        "\n",
        "del img,label\n",
        "assert label_patches.shape[:] == image_patches.shape[:-1]"
      ],
      "metadata": {
        "id": "hDPQa3U30tWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## evaluate your data\n",
        "evaluation = loaded_model.evaluate(image_patches,label_patches,batch_size = 4)"
      ],
      "metadata": {
        "id": "vYJ7ugcsPCn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## predict your data\n",
        "predictions = loaded_model.predict(image_patches,batch_size = 4, verbose = 1)\n",
        "predictions = np.squeeze(predictions,axis = -1)"
      ],
      "metadata": {
        "id": "aHVIktKe-HXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## list of patches that applied mask\n",
        "masks = get_masks(label_patches = label_patches,mask_mean=25)"
      ],
      "metadata": {
        "id": "7emA_TMh9N4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot predictions"
      ],
      "metadata": {
        "id": "U5dGZsKR-MB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_image = reconstruct_patch(image_patches,img_patch_shape)"
      ],
      "metadata": {
        "id": "suXijnbV4ELP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(reconstructed_image)"
      ],
      "metadata": {
        "id": "MBK_VarZExvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_pred = reconstruct_patch(predictions,label_patch_shape)"
      ],
      "metadata": {
        "id": "vXi-_PuVxTcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(reconstructed_pred,cmap='gray')"
      ],
      "metadata": {
        "id": "6fnQL4EKxX0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del image_patches,label_patches,reconstructed_pred,predictions"
      ],
      "metadata": {
        "id": "B3qjqBY8V3YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Driver Functions\n",
        "Test section to see functions work. (Do not run)"
      ],
      "metadata": {
        "id": "WGQm895_PgX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img,label,dataset_size = read_data() ## Sample image and label"
      ],
      "metadata": {
        "id": "nhD96CMBZKWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = rgb2gray(label)"
      ],
      "metadata": {
        "id": "9SWGmfHKaHKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_patches = patch_data(img,(256,256,3),256)"
      ],
      "metadata": {
        "id": "dsEqo2WZa0jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_patches = patch_data(label,(256,256),256)\n",
        "label_patches = np.where(label_patches<50,label_patches,255.)"
      ],
      "metadata": {
        "id": "xkrlUTAcgHKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del img,label"
      ],
      "metadata": {
        "id": "YNg7JukO2qpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert label_patches.shape[:] == image_patches.shape[:-1]"
      ],
      "metadata": {
        "id": "m2v5EcHDp0sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess**"
      ],
      "metadata": {
        "id": "OKNDmW2kp2Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = split(image_patches,\n",
        "                                      label_patches,\n",
        "                                      test_size = test_split_size)"
      ],
      "metadata": {
        "id": "mPPcFbFun2Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                             rotation_range = rotation_range,\n",
        "                             horizontal_flip =horizontal_flip,\n",
        "                             vertical_flip = vertical_flip,\n",
        "                             width_shift_range=width_shift_range,\n",
        "                             height_shift_range=height_shift_range)"
      ],
      "metadata": {
        "id": "cJiv08rwpuNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_patch = datagen.flow(x = x_train,\n",
        "                                   y = y_train,\n",
        "                                   batch_size = BATCH_SIZE,\n",
        "                                   seed = SEED)\n",
        "\n",
        "valid_dataset_patch = datagen.flow(x = x_test,\n",
        "                                   y = y_test,\n",
        "                                   batch_size = BATCH_SIZE,\n",
        "                                   seed = SEED)"
      ],
      "metadata": {
        "id": "heuxWZ1Npx7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph of some masks**"
      ],
      "metadata": {
        "id": "lmi8mD0_qAVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masks = get_masks()"
      ],
      "metadata": {
        "id": "0wX3PAUri8rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphify(masks[10:15],fig_size = 14)"
      ],
      "metadata": {
        "id": "g_SXLqwui-e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset_patch,\n",
        "                         batch_size = BATCH_SIZE,\n",
        "                         epochs= 11,\n",
        "                         callbacks = callbacks,\n",
        "                         workers = -1,\n",
        "                         validation_data = valid_dataset_patch,\n",
        "                         validation_steps = (len(x_test)//BATCH_SIZE),\n",
        "                         steps_per_epoch=(len(x_train)//BATCH_SIZE))"
      ],
      "metadata": {
        "id": "PUgvy3gRlkHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}